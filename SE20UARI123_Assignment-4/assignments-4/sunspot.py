# -*- coding: utf-8 -*-
"""sunspot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11zuN72j0_Gl9613AUu4U7vXYYybuF9Mi
"""

import os
import time

import math
import numpy as np
import pandas as pd
import seaborn as sns; sns.set(style="ticks", color_codes=True)

from sklearn.metrics import mean_absolute_error as MAE, mean_squared_error as MSE
from sklearn.model_selection import train_test_split, KFold
from sklearn.feature_selection import RFE

import matplotlib as mpl
import matplotlib.pyplot as plt
from IPython.display import display

from dateutil.parser import parse

date_parser = lambda date: parse(date)

df = pd.read_csv('/content/Sunspots.csv',
                 usecols=['Date', 'Monthly Mean Total Sunspot Number'],
                 parse_dates=['Date'],
                 date_parser=date_parser)
df.rename(columns={'Monthly Mean Total Sunspot Number': 'Monthly_Average_Sunspot'}, inplace=True)
df.head()

N_YEARS = 50
train_df = df[-2*N_YEARS*12:-N_YEARS*12]
test_df = df[-N_YEARS*12:]

train_size, test_size = len(train_df), len(test_df)
print(train_size, test_size)

compose_df = pd.concat([train_df, test_df])

plt.plot(train_df.Date, train_df.Monthly_Average_Sunspot, 'bo',
         test_df.Date, test_df.Monthly_Average_Sunspot, 'ro')

compose_df.set_index('Date').plot()

import tensorflow as tf
from tensorflow.keras.losses import Huber, Reduction

loss_func = Huber(delta=1.0,
                  reduction=tf.keras.losses.Reduction.NONE)

loss_df = pd.DataFrame()
loss_df['Date'] = test_df.Date

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from statsmodels.tsa.statespace.sarimax import SARIMAX
# 
# train_set = train_df.copy()
# train_set.set_index(keys='Date', drop=True, inplace=True)
# train_set.index = pd.DatetimeIndex(data=train_set.index.values,
#                                    freq=train_set.index.inferred_freq)
# print('Frequency by:', train_set.index.inferred_freq)
# 
# # https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html
# model = SARIMAX(endog=train_set['Monthly_Average_Sunspot'],
#                 exog=None,
#                 order=(1, 0, 2), # p,d,q - number of AR parameters, differences, and MA parameters
#                 seasonal_order=(1, 0, 2, 12*11), # P,D,Q,s - AR parameters, differences, MA parameters, and periodicity
#                 seasonal_periods=2,
#                 trend='ct', # c: const - t: time
#                 enforce_invertibility=False,
#                 enforce_stationarity=True)
# 
# # https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.fit.html#statsmodels.tsa.statespace.sarimax.SARIMAX.fit
# ARIMA = model.fit(maxiter=50,
#                   optim_score='approx',
#                   cov_type='approx',
#                   method='bfgs',
#                   disp=True)

forecast = ARIMA.predict(start=train_size,
                         end=train_size+test_size-1)
forecast = pd.DataFrame(forecast.values, index=test_df.index, columns=['Prediction'])

forecast['Date'] = test_df.Date
plt.plot(train_df.Date, train_df.Monthly_Average_Sunspot, 'ro',
         test_df.Date, test_df.Monthly_Average_Sunspot, 'yo',
         forecast.Date, forecast.Prediction, 'bo')

loss = loss_func(test_df.Monthly_Average_Sunspot.values.reshape(-1,1),
                 forecast.Prediction.values.reshape(-1,1)).numpy()
loss_df['SARIMA'] = loss
loss_df['SARIMA'].describe()